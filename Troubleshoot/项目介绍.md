# 项目介绍

## 项目名称

故障排查与恢复：Kubernetes 集群与业务连续性实战

## 项目背景

- 实验环境基于 VMware vSphere，分组 team03–team12；每个组包含 `master01`、`node01`、`node02`，其中 `master01` 同时作为本组 NFS 服务器。
- 由于 IP 冲突与组网调整，需要将集群关键组件中的 `10.3.201.*` 统一变更为 `10.3.X.Y`，引发控制平面连接异常、证书 SAN 不匹配、kube-proxy 配置错误、Calico token 创建失败等问题。
- 业务侧采用 LNMP 架构（Nginx + PHP-FPM + MySQL）与 Redis，静态与数据目录通过 NFS 挂载；对外通过 Ingress 暴露为 `bbs.iproute.cn`，需在网络与配置修复后恢复业务可用性。

## 项目价值

- 快速恢复：提供从控制面到工作节点的系统化故障处置流程（配置变更、证书重建、服务重启、节点重置与重加入），显著缩短恢复时间。
- 稳定性提升：标准化配置管理（ConfigMap、证书 SANs、kubeadm/kubelet 配置）以降低人为失误和环境漂移导致的风险。
- 业务连续性：通过健康检查、NFS 持久化、数据库密码与配置同步确保 `bbs.iproute.cn` 在网络变更后仍能快速恢复。
- 能力培养：覆盖网络、存储、计算、容器编排与中间件的联动排障，提升 SRE/DevOps 的实战能力与工程化素养。
- 可扩展性：提供 HPA/VPA、MySQL 主从与读写分离、Redis 哨兵等扩展方案，为容量规划与高可用架构打下基础。

## 技术栈

- 容器与编排：`Docker`、`Kubernetes (kubeadm)`
- 容器网络：`Calico`、TLS 证书管理（`apiserver` SANs）、`iptables`
- 存储与配置：`NFS`、`ConfigMap`、`PV`、`PVC`
- 中间件与业务：`Nginx`、`PHP-FPM`、`MySQL`（主从/读写分离）、`Redis`（持久化/哨兵）
- 自动化与扩缩容：`HPA`、`VPA`
- 环境与平台：`VMware vSphere`、`Linux`

## 实战要求

1. 每天中午12点前发布任务和视频
2. 需要在第二天中午12点前完成任务并输出故障排查和恢复过程文档记录/恢复后截图

## 任务列表

### Day01

1. 将每个节点的IP地址更改为自己所属分组的网段IP
2. `kubectl get nodes -o wide`命令输出的集群信息异常，排查并恢复正常


### Day02

1. `kube-system`命名空间里 calico 网络组件异常，排查并恢复正常
2. 确保`kube-system`命名空间里所有 Pod 都运行正常

### Day03

1. 将`/root/resources/01.nginx.yaml,02.phpfpm.yaml,03.mysql.yaml`等文件中 NFS 地址指向本集群 master01
2. 为`nginx.yaml,phpfpm.yaml`等文件添加健康检查机制
3. 检查`nginx php-fpm mysql`服务
4. 通过`bbs.iproute.cn`访问正常

### Day04

1. 更新 MySQL 密码为`123456`后访问`bbs.iproute.cn`正常
2. Redis 配置文件通过 Configmap 挂载至`/usr/local/etc/redis/redis.conf`，数据目录通过 NFS 挂载至`/data`并测试验证数据持久化符合预期

### Day05

1. 新增工作节点 node03，测试验证集群节点数量增加后业务是否正常
2. 水平扩缩容：参考 `HPA控制器` 实验，根据策略的阈值扩缩容 POD 副本数量
3. [扩展] 垂直扩缩容：根据策略扩缩 pod cpu/mem 的 request 和 limit
4. [扩展] Master 节点的高可用方案
5. [扩展] 基于 K8s 的 MySQL 高可用方案
6. [扩展] 基于 K8s 的 Redis 高可用方案
